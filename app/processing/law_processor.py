import requests
import xml.etree.ElementTree as ET
from urllib.parse import quote
import re

OC = "chetera"
BASE = "http://www.law.go.kr"

def get_law_list_from_api(query):
    exact_query = f'\"{query}\"'
    encoded_query = quote(exact_query)
    page = 1
    laws = []

    while True:
        url = f"{BASE}/DRF/lawSearch.do?OC={OC}&target=law&type=XML&display=100&page={page}&search=2&knd=A0002&query={encoded_query}"
        res = requests.get(url, timeout=10)
        res.encoding = 'utf-8'
        if res.status_code != 200:
            break

        root = ET.fromstring(res.content)
        found = 0
        for law in root.findall("law"):
            name = law.findtext("ë²•ë ¹ëª…í•œê¸€", "").strip()
            mst = law.findtext("ë²•ë ¹ì¼ë ¨ë²ˆí˜¸", "")
            detail = law.findtext("ë²•ë ¹ìƒì„¸ë§í¬", "")
            full_link = BASE + detail
            laws.append({"ë²•ë ¹ëª…": name, "MST": mst, "URL": full_link})
            found += 1

        if found < 100:
            break
        page += 1

    return laws

def get_law_text_by_mst(mst):
    url = f"{BASE}/DRF/lawService.do?OC={OC}&target=law&MST={mst}&type=XML"
    try:
        res = requests.get(url, timeout=10)
        res.encoding = 'utf-8'
        if res.status_code == 200:
            return res.content
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ë³¸ë¬¸ ìš”ì²­ ì‹¤íŒ¨ (MST={mst}):", e)
    return None

def clean(text):
    return re.sub(r"\s+", "", text or "")

def highlight_if_contains(text, keyword):
    if keyword in clean(text):
        return re.sub(f"({re.escape(keyword)})", r"<span style='color:red'>\1</span>", text or "")
    return text or ""

def get_highlighted_articles(mst, keyword):
    xml_data = get_law_text_by_mst(mst)
    if not xml_data:
        return "âš ï¸ ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    tree = ET.fromstring(xml_data)
    articles = tree.findall(".//ì¡°ë¬¸")
    results = []

    for article in articles:
        jo = article.findtext("ì¡°ë²ˆí˜¸", "").strip()
        title = article.findtext("ì¡°ë¬¸ì œëª©", "") or ""
        content = article.findtext("ì¡°ë¬¸ë‚´ìš©", "") or ""
        í•­ë“¤ = article.findall("í•­")

        ì¡°ë¬¸_ì¶œë ¥ëŒ€ìƒ = False
        í•­_í…ìŠ¤íŠ¸ë“¤ = []

        for hang in í•­ë“¤:
            ha = hang.findtext("í•­ë²ˆí˜¸", "").strip()
            text = hang.findtext("í•­ë‚´ìš©", "") or ""
            if keyword in clean(text):
                ì¡°ë¬¸_ì¶œë ¥ëŒ€ìƒ = True
            í•­_í…ìŠ¤íŠ¸ë“¤.append((ha, text))

        if keyword in clean(content) or keyword in clean(title):
            ì¡°ë¬¸_ì¶œë ¥ëŒ€ìƒ = True

        if ì¡°ë¬¸_ì¶œë ¥ëŒ€ìƒ:
            output = f"<br><strong>ğŸ“Œ ì œ{jo}ì¡° {highlight_if_contains(title, keyword)}</strong><br>"
            output += f"{highlight_if_contains(content, keyword)}<br>"
            for ha, text in í•­_í…ìŠ¤íŠ¸ë“¤:
                í•­ì¶œë ¥ = highlight_if_contains(text, keyword)
                output += f"ì œ{ha}í•­: {í•­ì¶œë ¥}<br>"
            results.append(output)

    if not results:
        return "ğŸ” í•´ë‹¹ ë‹¨ì–´ë¥¼ í¬í•¨í•œ ì¡°ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."
    return "".join(results)
